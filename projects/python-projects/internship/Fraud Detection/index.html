<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Fraud Detection Project (Internship)</title>
  <link rel="stylesheet" href="../../../../assets/css/style.css" />
</head>
<body>
  <nav>
    <a href="../../../../index.html">Home</a> |
    <a href="../../../../about.html">About</a> |
    <a href="../../../index.html">Projects</a> |
    <a href="../../../../contact.html">Contact</a>
  </nav>

  <h1>Fraud Detection Project (Internship)</h1>
  <p>
    This project was completed during my internship and focused on building a fraud detection model
    for financial transactions. The dataset was highly imbalanced, with fraudulent events representing
    only a small fraction of total transactions. I performed exploratory data analysis, feature engineering,
    and developed multiple models including Logistic Regression, Decision Trees, Random Forest,
    and XGBoost. Evaluation centered on metrics such as Accuracy, Precision, Recall, F1-score, and ROC-AUC.
    The best-performing models significantly improved recall while maintaining precision, helping reduce false positives
    and allowing risk teams to prioritize reviews more effectively.
  </p>

  <h2>üìÇ Reports & Documentation</h2>
  <ul>
    <li><a href="EDA.html" target="_blank">Exploratory Data Analysis (EDA)</a></li>
    <li><a href="FraudDeterction.html" target="_blank">Model Development & Evaluation</a></li>
    <li><a href="Fraud Detection Used Case.pptx" target="_blank">Presentation Deck (PPTX)</a></li>
    <li><a href="README.md" target="_blank">Raw README (Markdown)</a></li>
    <li><a href="README.html" target="_blank">Formatted README (HTML)</a></li>
  </ul>

  <h2>üìä Dataset</h2>
  <p>
    Due to file size constraints, the dataset is hosted on Kaggle:
    <a href="https://www.kaggle.com/competitions/home-credit-default-risk/data" target="_blank" rel="noopener">
      Home Credit Default Risk Dataset (Kaggle)
    </a>
  </p>

  <h2>üìò Overview</h2>
  <p>
    The project involved handling highly imbalanced data, creating domain-specific features,
    and comparing several machine learning models. Evaluation focused on metrics like Accuracy,
    Precision, Recall, F1-score, and ROC-AUC to assess model effectiveness.
  </p>

  <h2>üõ†Ô∏è Skills & Tools Applied</h2>
  <ul>
    <li>Python: pandas, numpy, scikit-learn, xgboost</li>
    <li>Exploratory Data Analysis (EDA)</li>
    <li>Data visualization: matplotlib, seaborn</li>
    <li>Handling class imbalance (stratified CV, class weights)</li>
    <li>Model evaluation: Accuracy, Precision, Recall, F1-score, ROC-AUC</li>
  </ul>
</body>
</html>
