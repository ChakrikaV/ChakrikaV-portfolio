# Fraud Detection Project (Internship)

This project was completed during my internship as part of a fraud detection use case. The objective was to identify suspicious transactions more effectively while reducing false positives, giving analysts higher confidence in alerts.  

The project exposed me to handling **real-world imbalanced data**, **feature engineering**, and **model evaluation** in a high-stakes setting.

---

## üìÅ Files Included

- `EDA.html`: Exploratory Data Analysis of the transaction dataset.  
- `FraudDeterction.html`: Model development and evaluation notebook (exported to HTML).
- `Fraud Detection Used Case.pptx`: Cleaned presentation deck summarizing the project.    
- `README.md`: Raw project description.  
- `README.html`: Formatted, portfolio-ready project description.  

---

## üìä Project Overview

The use case focused on predicting the likelihood of fraudulent activity from transaction data.  
This project was designed to:  
- Apply advanced machine learning models in a business context.  
- Handle severe class imbalance and optimize for operationally relevant metrics.  
- Deliver NDA-safe insights and summaries of model performance.  

---

## üß™ Models Explored

Several algorithms were evaluated to balance precision and recall:  
- **Logistic Regression**  
- **Random Forest**  
- **XGBoost**  
- **Support Vector Machine (SVM)**  

Each model was tuned and compared across multiple evaluation metrics.  

---

## ‚öôÔ∏è How to Run

1. Open the HTML reports (`EDA.html` or `FraudDeterction.html`) directly in a browser to review the analysis.  
2. Original development was done in Jupyter Notebook with Python.  

---

## üõ†Ô∏è Tools & Libraries Used

- `pandas`  
- `numpy`  
- `scikit-learn`  
- `xgboost`  
- `matplotlib` / `seaborn`  
- `SQL` (for initial data handling)  

---

### üîñ Notes

This project was part of my internship experience. All details here are **NDA-safe** and generalized. The work taught me how to:  
- Engineer domain-specific features (e.g., velocity and frequency features).  
- Handle class imbalance using stratified sampling and class weights.  
- Align model outputs to real-world review capacity (e.g., tuning thresholds for Precision@K).  
